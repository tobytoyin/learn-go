---
id: 3A450599-927E-4832-8516-7BD6798F54B4
creation-date: 2023-10-05T14:11:54
type: walkthrough
aliases:
  - Dockerfile for LLaMa model
tags:
  - containers
  - devops
  - example
---

Here is a sample Dockerfile to build: 
- [[0_pages/02/2023-03-20-12-21-40-09600|Poetry Project]]
- Download the Llama LLM using Git Large Files Sharing

```yaml
FROM python:3.10.13-slim

ENV WORKDIR=/working
ENV PORT=8000
ENV FORCE_CMAKE=1
ENV CMAKE_ARGS=-DLLAMA_OPENBLAS=on

WORKDIR /working
COPY . /working

# pip setups
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    software-properties-common \
    git \
    git-lfs \ 
    && rm -rf /var/lib/apt/lists/*

# download a gguf model
RUN git lfs install \
    && GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF \
    && cd CodeLlama-7B-Instruct-GGUF \ 
    && git lfs pull --include "codellama-7b-instruct.Q4_K_M.gguf" \
    && mv ./codellama-7b-instruct.Q4_K_M.gguf /working/models/

RUN pip3 install --upgrade pip \
    && pip3 install setuptools poetry

RUN poetry config virtualenvs.create false\
    && poetry install

EXPOSE 8000

CMD ["poetry", "run", "python3", "llm/main.py"]
```

---
## ℹ️  Resources
- 