---
id: 24E69529-1A84-47DB-9822-C9185A182B66
creation-date: 2023-01-08T17:35:39 
type: walkthrough
alias: ['Spark Temporary Writes', 'cache', 'checkpoint']
tags: [ technology/spark/pyspark, technology/spark ]
---

## Cache 

![[3_hidden/_images/Pasted image 20221218231605.png]]

*Caches* are RDDs stored in-memory, this **allows persistent and fast retrieval during application runtime**. 

Cache lifetime is within the Spark application, which are removed when the application terminates. This makes it useful to share data and avoid re-computation across a running Spark application. 

---
## Checkpoint 

![[3_hidden/_images/Pasted image 20221218232230.png]]

*Checkpoints* are stored on disk within a file system, i.e., writing the RDDs to disks. This means Spark would create files that lasted after an application runtime ends.

Checkpoints lifecycle is permanent inside a file system (unless being removed). This makes it useful to share data across different [[0_pages/05/2023-02-26-15-35-58-33600|batch jobs]]; and allow different applications to read those RDDs directly (**this needs to be in the same Spark Context**).

### Additional Configs
Checkpoints required additional configs during instantiation/ runtime: 
- `sc.setCheckpointDir` - a tmp path within a File System (e.g., HDFS, S3)
- `spark.cleaner.referencetracking.cleancheckpoints`: 
	- config value in Spark to determine whether RDDs should be removed afterwards or not
	- `sc.getConfig().set(configKey, configVal)` to set this during runtime

---
## ℹ️  Resources
- [[Apache Spark The Definitive Guide#^chapter-13]]