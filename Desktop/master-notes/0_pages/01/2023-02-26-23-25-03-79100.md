---
id: 88DC6FC5-2015-4083-A766-15D9FF69FD28
creation-date: 2023-01-11T22:26:09
type: concept
aliases:
  - Spark Memory & Garbage Collection
  - garbage collection
tags:
  - optimisation
  - technology/spark
catalogs:
  - 2023-01-11-22-38
---

# Spark Memory & Garbage Collection 

While [[0_pages/03/2023-02-26-17-20-20-43600|cache]] is generally a good way to cache dataset to reuse it in future Tasks, too many caches would often lead to poor [[0_pages/02/2023-02-27-21-08-59-74100|performance]] because Spark needs to invoke *Garbage Collection*. 

---
## Spark Heap Objects

Objects in Spark are stored in-memory as JVM [[0_pages/04/2023-04-20-23-03-40-71200|Heap Object]] (i.e., tree like structured determines by their lifetime in an application). There are different types of objects being generated when Spark Tasks run: 

![[3_hidden/_images/Pasted image 20230420230309.png|500]]
- *Heap Regions* 
	- there are two Heap regions: *Old & Young Heaps*
	- *Old Heap* region mainly for long-lasting objects, these objects are intended to be accessed (mostly) throughout the application lifecycle
	- *Young Heap* regions are for short-lived objects, they are intended for temporary access and quickly handling immediate tasks
- *Collected RDD* 
	- these are intermediate results (akin to variables) that are generated during a Task run
	- they are stored in the "*Young Heap*" called *Eden*
	- while *Survivors* are reserved for RDDs that lived sufficiently long within an application
- *Cached RDD* - are intended to be reused and are stored in the Old region

---
## Minor Garbage Collection

![[3_hidden/_images/Pasted image 20230423133601.png|500]]
*Minor Garbage Collection* mainly indicates the ==process of moving more recent objects to a "older" heap==. This allows Spark to have quicker access to *Eden* in order to complete the Tasks at hand. Garbage Collection mainly triggered by two scenarios: 

- *Heap is full* 
	- a particular region is full, thus all objects in heap(s) are moved to another region to free-up quicker access
	- all Eden + Survivor 1 RDDs are moved to Survivor 2 whenever Eden is full
	- all Survivor 2 RDDs moved to Old regions when Survivor 2 is full
- *Exceed certain lifetime*
	- any "Young Heap" objects lived sufficiently long in an application, they are dumped into a "older" region
	- e.g., Eden dumps to Survivor 1, ....., Survivor 2 dumps to Old

---
## Full Garbage Collection

Since objects are consecutively dumping to "older" heaps during minor garbage collections, the Old Heap would eventually get full. When this happens, a *Full Garbage Collection* would start. 

![[3_hidden/_images/Pasted image 20230111232342.png|500]]
A Full Garbage Collection exhaustively conducts two processes: 
1. trace all objects in the Heap across all regions > check if they are unreferenced in the DAG > deleting them from memory
2. reallocation of all objects within the Heap to fill up unused space

Because these processes are exhaustive (operations on all objects), a full garbage collection itself is computationally expensive. Every time a full garbage collection is invoked, the current tasks would be paused. 

---
## ℹ️  Resources
- [[Apache Spark The Definitive Guide#^chapter-19]]