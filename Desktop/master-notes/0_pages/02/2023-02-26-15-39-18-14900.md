---
id: 43C43DDB-5628-4FB5-8CE8-658D71916859
creation-date: 2022-12-11T15:44:06
type: concept
aliases:
  - MapReduce
  - MapReduce Parallelism
  - Distributed MapReduce
  - Mapping Stage
  - Reduce Stage
  - shuffling
tags:
  - distributed-computing
  - distributed-computing/distributed-data
catalogs:
  - 2022-12-11-15-57
---

# MapReduce   

---

   

Batch Processing in a [[0_pages/03/2023-02-26-17-09-32-97200|distributed system]] mainly involves two key components: [[0_pages/02/2023-02-26-17-18-40-81800|MapReduce]] and [[0_pages/03/2023-02-26-17-12-01-86700|partition]]. A distributed MapReduce processing system follows a similar workflow of a single machine MapReduce: *map-sort-reduce*.

> [!note]- MapReduce Parallelism vs Traditional Parallelism
> 
> Although MapReduce can perform parallel computing in a distributed system, the setup is much simpler than traditional Parallelism. This is because ==MapReduce can handle Records independently without knowing where the inputs and outputs locations==. This allow Parallelism without a central Node to spawn parallel resources and keep track of the event loop. 

Compare to a [[0_pages/02/2023-02-26-17-18-40-81800#^3d30e2|non-distributed MapReduce]], the distributed workflow is fairly similar. The difference is that a distributed MapReduce operates on a partitioned file system.

![[3_hidden/_images/map-reduce-20221211172934.png|700]]

In a distributed MapReduce framework, all the computation are done in 3 major steps: 
- Mapping Stage - extract keys & values ^89e6ef
- Shuffle Stage - partition same key Records
- Reducing Stage - computation on partitions

---
## 🗺️ Mapping Stage

![[3_hidden/_images/mapping-20221211173712.png|500]] 

The Mapping Stage works similar to single machine MapReduce: 
1. All files stored in a partitioned file structure (usually within a single Data Node) would parse into separate Records, then each Record callback a Mapper Function.  ^628c1f
2. Either extracting keys from the Record or generate a new Hash Key. Mapper Function pair the key with the mapper function output values.

--- 
## 🔀 Shuffle Stage

![[3_hidden/_images/Pasted image 20221213152112.png|500]] 

Distributed MapReduce add an additional step which is to shuffle Records to different Reducers. This is by using the Output Record's Hash Key to conduct repartitioning ([[0_pages/03/2023-02-26-15-38-47-17000|Hash Key Partitioning]]) and copy Records with the same key into a new Partition before doing computation. 

> [!note]- Why Shuffling is required?
> The partitions of a file system might not always suitable for batch processing. For example, a file system might have too small number of partitions, thus lead to higher [[0_pages/03/2023-02-26-17-12-42-45600|hotspots]]. Therefore, by shuffling all the records, it can ensure the MapReduce can have an evenly distributed computation.

---
## 💧 Reduce Stage

The Reduce Stage operates in the same way, that: 

![[0_pages/02/2023-02-26-17-18-40-81800#^ec02e6]]

The only difference is that Output Records are then written in a Node of the distributed file system.

---
## ℹ️ Resources
- [[📕 Design Data-Intensive Applications#^batch-process]]