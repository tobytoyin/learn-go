---
creation-date: 2022-12-27T17:08:02
type: walkthrough
aliases: []
tags:
  - aws
  - devops
  - use-cases
  - cloud-computing
---
# Basic EMR EC2 Example    

## EMR High Level Design

![[1_catalog/14/2022-12-29-21-32#^fff501]]


To setup an EMR application ([[0_pages/01/2023-02-26-13-53-36-93000#‚ùê Deployment Mode|EC2 Mode]]), we need to setup several key steps for this:
- [[#1. üï∏ Cluster's Network]]
- [[#2. Cloud Client]]
- [[#3. EMR Cluster Configuration]]
- [[#4. üö¶ Expose EMR Cluster to Client]]
- [[#5. Setting Up S3 Resources]]
- [[#6. Connect to Cluster with SSH]]
- [[#7. Execute Spark Job]]

---
## 1. üï∏  Cluster's Network

![[1_catalog/14/2022-12-29-21-32#^5e0e9d]]

A Cluster contains its own [[0_pages/01/2023-03-13-21-42-03-20900#^a37d7e|network]]. We can setup a network using *AWS VPC* with a single public subnet (i.e., public IP address) that can be accessed by other authorised machines. This network would later serve as our *Cluster Network*.  

---
## 2. Cloud Client

To run Spark in a Cluster, we need a machine that can `spark-submit` to the EMR cluster. 

![[1_catalog/14/2022-12-29-21-32#^5e0e9d]]

We can use *AWS Cloud9* to create a cloud machine (i.e., [[0_pages/02/d-2023-11-07-20-55-47|EC2]]) to serve as an access point to the EMR cluster through the VPC network (This can also be any machine that have the tokens to connect to the network). 
For security, we can also setup a *EC2 Key Pairs* as a security key to the cloud instance. 

---
## 3. EMR Cluster Configuration

![[1_catalog/14/2022-12-29-21-32#^f9a3ab]]

To setup a [[0_pages/02/2023-02-26-14-00-02-41200|EMR Cluster]], we need to define our *Software Configuration* (storage, processing software, metastores etc). 

As a *Hardware Configuration* we need to define:
- how powerful should the [[0_pages/01/2023-02-26-14-21-05-00600|Nodes]] be (instance type)
- how many Nodes to reserve (number of Masters, Core, Task Nodes) 
- attach this cluster to the Network defined earlier, which officially making it its Cluster Network.

For the other system aspect, we need to select the S3 location to store the *Monitoring Logs*; additional EC2 Security Key when making request to the Cluster.  

> [!example]- AWS Console
> In the advance option, we select several big data processing software like Spark (processing), Hadoop (node managing), Presto (storage). Additional we can use Glue Data Catalog as a [[0_pages/01/2023-02-26-13-53-36-93000#üè™ Metastores Selection|persistent and managed metastore]]. 
> 
> ![[3_hidden/_images/emr-cluster-setup-20221229220342.png]]
> ![[1_catalog/14/2022-12-30-11-33#^4d6883]]

---
## 4. üö¶ Expose EMR Cluster to Client

Now that the EMR cluster is set, we need to allow the [[#Cloud Client|cloud instance]] to communicate with the cluster through SSH. 

We need to obtain several things: 
- the instance(s) that run the cluster's Master Node
- the cluster network address that exposes for authorised traffic (i.e., subnet's IPv4)

![[1_catalog/14/2022-12-29-21-32#^d3acbd]]

We need to *configure the Inbound Rule* of the EC2 Master Node to allow SSH traffic into a exposed IPv4 (e.g., 10.0.0.0/xx). 

> [!example]- AWS Console
> 1. First find the Master Node security setting inside your EMR cluster:
> 
> ![[1_catalog/14/2022-12-30-11-33#^50350d]]
> 
> ---
> 2. Then select the "Master Node Security Group" and choose "edit Inbound Rules": 
> 
> ![[3_hidden/_images/Pasted image 20221230122001.png|500]]
> 
> ---
> 3. Add a "allowed" IPv4 address that allow authorised traffic to execute SSH: 
> 
> ![[3_hidden/_images/Pasted image 20221230122059.png]]
> 

---
## 5. Setting Up S3 Resources

We need to have some resources store in our S3 bucket for the EMR cluster, i.e., Spark scripts, source data etc. We can also include some placeholder folder for the cluster, i.e., "logs" for logging; "output" for spark outputs. 
<sub>(Note: These resources are usually done by a CI/ CD process)</sub>

> [!example]- S3 Structure
> ![[3_hidden/_images/Pasted image 20221230144030.png]]

> [!example]- Sample Data
> Our `source-data/sample-data.csv` is a very simple dataset for us to do aggregation of the `id` column: 
> 
> ![[3_hidden/_images/Pasted image 20221230144140.png|300]]

> [!example]- Spark Script
> And out spark script thats in 2 positional arguments as `spark submit <input-s3> <output-s3>`: 
> 
> ![[1_catalog/14/2022-12-30-11-33#^b014dd]]
> 

---
## 6. Connect to Cluster with SSH

To use our cloud instance to connect to the EMR cluster, we need to obtain couple of information: 
- *Master Public DNS* of  the cluster - this is the address of the cluster to SSH into
- *Uploaded Public Key* - `.pem` file created [[#2. Cloud Client|earlier]] to provide us authorised access

Inside the cloud terminal, we execute the SSH connection through: 

```bash
# change public key to "read only"
chmod 400 <<pem-key>>  
# ssh into cluster
ssh -i <<pem-key>> hadoop@<<emr-master-public-dns-address>>
```

> [!example]- AWS Console
> With those commands executed, we should see: 
> 
> ![[3_hidden/_images/Pasted image 20221230151044.png]]

---
## 7. Execute Spark Job

Once we are in the cluster's Master Node terminal, we can [[0_pages/02/2023-03-05-17-30-33-26300|deploy our Spark job]]: 

```shell
spark-submit <<spark-s3-uri>> <<input-s3>> <<output-s3>>
```

> [!example]- Example
> For example, we execute the below command from SSH shell: 
> ![[3_hidden/_images/Pasted image 20221230152109.png]]
> 
> Once the job is completed, our S3 will show the results as: 
> ![[3_hidden/_images/Pasted image 20221230152137.png]]

---
## ‚ÑπÔ∏è¬† Resources
- [AWS Skillbuilder - Getting Started with Amazon EMR](https://explore.skillbuilder.aws/learn/course/8827/play/40942/getting-started-with-amazon-emr;lp=97)