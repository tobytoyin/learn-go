---
id: 260CAF33-9DC2-43FD-9224-F0F5A9832F35
creation-date: 2023-02-12T15:59:55 
type: concept
alias: ['Graphs Convolution Variation ', 'convolution', 'adjancy matrix']
tags: [ machine-learning/graph-model, linalg]
---

# Graphs Convolution Variation 

In [[0_pages/05/2023-02-26-17-06-58-65100|graph convolution]], the default operation $h_{conv} = \sum_{i=0}^{d}A^dh$ is a sum aggregation convolution. 

---
## Sum Convolution

The basic one is *sum convolution*, which is simply a matrix multiplication: 
- In matrix form - $Conv(h) = \sum_{i=0}^{d}A^dh$
- In iterative form - $Conv(h_v) = \sum{h_u}$ over the neighbour Nodes

--- 
## Average Convolution


> [!NOTE]- Degree Matrix
> *Degree Matrix* $D$ is a matrix indicates the number of immediate neighbours of the Nodes. It is the row summation of Adjacency Matrix $A$ multiply to a diagonal matrix. 

*Average convolution* can be done by multiplying the averaged Adjacency Matrix $A_{avg}$ instead of the unweighted one. where $A_{avg} = D^{-1}A$.
- In matrix form - $Conv(h) =\sum_{i=0}^{d}A_{avg}^dh$ 
- In iterative form - $Conv(h_v) = \frac{1}{N(u)}\sum{h_u}$

Note: $N(u)$ is the number of neighbours Nodes, as `len(neighbours)` in pseudo

---
## ℹ️  Resources
- [Youtube](https://www.youtube.com/watch?v=ijmxpItkRjc)