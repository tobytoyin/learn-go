---
id: C344BCA8-55B3-4F1D-A5F9-4AFBABFC6A66
creation-date: 2023-07-22T14:14:05
type: walkthrough
aliases: 
tags:
  - k8s
title: HorizontalPodAutoscaler Walkthrough
---

# HorizontalPodAutoscaler Walkthrough

The [[0_pages/03/d-2023-07-18-21-10-47|HorizontalPodAutoscaler]] example follows the example provided by Kubernetes documentations

---

## 1. Setting up Metric Server

To allow the Worker Nodes kubelet to expose its Metrics to the Control Panel, it needs to deploy a `metric-server`. See [here](https://github.com/kubernetes-sigs/metrics-server/tree/master). Sometime, a cluster might not be abled to start the server, we need to change the `--kubelet-insecure-tls` flags in the `metric-server` manifest when starting that container: 

```yaml
# components.yaml downloaded from metric-server's git
...
spec:
  selector:
    matchLabels:
      k8s-app: metrics-server
	...
    spec:
      containers:
      - args:
        - --cert-dir=/tmp
        - ...
        - --kubelet-insecure-tls=true  # add this
```

We can check if the `metric-server` is running in the cluster using: 

```bash
kubectl get deployment --all-namespaces | grep metrics-server

# kube-system  metrics-server  1/1  1  1  4m20s
```

---
## 1. Setting Up Services

Now we are going to set up a dummy server Deployment and linking all Pods created in this ReplicaSet into the same Service. We are using a pre-defined manifest: 

```shell
kubectl apply -f https://k8s.io/examples/application/php-apache.yaml
```

This creates: 
- ReplicaSet for deployment - one Pod with PHP image exposing port 80; Pods from this ReplicaSet are labelled as `run=php-apache` 
- Create a [[0_pages/02/2023-02-26-23-24-13-54500|Service]] that wrapped around `run=php-apache` label and exposing all of their port 80

Then we can check by:

```shell
# check number of pods in cluster
kubectl get pods

# check running services in cluster
kubectl get services
```

---
## 2. Generating Simple Autoscaler
We can generate a simple autoscaler based on a pre-defined metric and use that as our Based Autoscaler template for more complicated metrics targets: 

```shell
# create a simple autoscaler
kubectl autoscale \
	deployment php-apache \
	--cpu-percent=50 --min=1 --max=10
```

This means: 
- use `autoscale` API
- scale by making a deployment on a ReplicaSet called `php-apache`
- monitor CPU Percent (all Pods averaged) as target metric
- Scale at least 1 ReplicaSet & at most 10 ReplicaSet

```shell
# check running horizontal autoscaler
kubectl get hpa

# example hpa as yaml for specific deployment set
kubectl get hpa php-apache -o yaml > <fname>.yml
```

---
## 3. Test Autoscaler

We can test that the autoscaler is working by making lots of server requests using `wget` to increase the CPU load of the Pods. Then by checking the autoscaler, it will show that the ReplicaSet is able to scale up when the CPU Usage is exceeded the 50% target. 

![[3_hidden/_images/Pasted image 20230722184943.png]]

---
## 4. Understanding Autoscaler Manifest

We can modify the Manifest to create more complex scaling scaling rules: 
- monitor multiple metrics instead of one
- monitor custom metrics instead of pre-defined Metric API values

The Manifest structures in this way: 
- `scaleTargetRef` - what "kind" of resources should HPA target to scale
- `metrics` - what types of metrics should HPA monitor 
- `metrics.target` - the specific metrics to monitor and the target Metric threshold
- `status` - represents the current states and metrics monitoring done by HPA

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: <hpa-name>
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: <deployment-name>
  minReplicas: <min>
  maxReplicas: <max>
  metrics:
  - resource:
      name: cpu
      type: Resource
      target:
        averageUtilization: 50
        type: Utilization

status:
  observedGeneration: 1
  lastScaleTime: <some-time>
  currentReplicas: 1
  desiredReplicas: 1
  currentMetrics:
  - type: Resource
    resource:
      name: cpu
      current:
        averageUtilization: 0
        averageValue: 0
```

> [!Tip]- Types of Metrics
> In the Manifest, there are couple of `metrics.resources` use to scale: 
> - `Type=Resource` - representing metrics at the Container's aggregation
> - `Type=Pods` - representing *Averaged metrics* across selected Pods
> - `Type=Object` - representing *Averaged metrics* of different Objects (i.e., specific targeted "[[0_pages/02/2023-02-26-17-24-34-92400|kind]]") under the same namespace

---
## Deploy HPA using Manifest

When using a manifest to apply a new HPA, we can use the similar YAML as the above (except the `status` field which is not required in applying manifest). For example, we have a sample manifest that contains 3 Types of metrics: 

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: php-apache
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: php-apache
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  - type: Pods
    pods:
      metric:
        name: packets-per-second
      target:
        type: AverageValue
        averageValue: 1k
  - type: Object
    object:
      metric:
        name: requests-per-second
      describedObject:
        apiVersion: networking.k8s.io/v1
        kind: Ingress
        name: main-route
      target:
        type: Value
        value: 10k
```

We can replace & create a new HPA using: 

```shell
# (optional) if HPA already exists run this
kubectl delete hpa <hpa-name>

# create a new hpa
kubectl create -f <new-hpa-yml>

# check
kubectl get hpa
```


---
## ℹ️  Resources
- [HorizontalPodAutoscaler Walkthrough | Kubernetes](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/)