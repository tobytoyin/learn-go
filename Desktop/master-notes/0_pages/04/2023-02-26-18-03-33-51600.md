---
creation-date: 2023-02-26T18:03:33
type: walkthrough
aliases:
  - flatten-unnest
  - normalise JSON
tags:
  - technology/spark/pyspark
  - use-cases
---

# PySpark - Flatten Complex Nested Data

When working with JSON, Spark schema is often nested in either `Struct` and/or `Array`. It is often that these data needs to be normalised (flatten-unnest) in ETL. 

---
## 🏆 Goals 

- generalised way `explode` n-levels
	- because `col.*` could only access 1 level below the root level and this needs to be done recursively
- showing parent-child relationship
	- Because we might have same named columns under two different nest, this might lead to duplicated column names. We need a **reliable prefix that can show the parent-child relationship**

---
## Description of Use Case

We can achieve this by the follow key steps: 
- [[#1. Flatten Schema]] - to keep track of all columns' names, levels, parents, dtypes
- [[#2. Generalise Normalise]] - first explode `Array[T]`, then: 
	- to determine whether to explode then unnest `Struct[T]`
	- to flatten then unnest `Array[Struct[T]]`
3. explode order inference - to explode fields in proper order, i.e., explode all fields closest to the root first, then move one level higher, etc. 

These compose of one explode-unnest step, which then can be recursively calling on every columns (unnested one; other nested one) recursively until all steps are done. 

---
## 1. Flatten Schema

We need to have an easy access of schematic information about the nested dataframe, so that we can sort the exploding order. This allows us to later: 
- order to explode orders
- get the full name under parent-child relationship
- determine how to proceed with explode, i.e., struct vs array unnest

> [!Example]- `flatten_schema()`
> ![[3_hidden/_images/Pasted image 20230226191148.png]]

---
## 2. Generalise Explode

When doing an `explode` operation on `Array[T]`, we would face two scenarios: 
- getting a clean `Struct[T]` that can be unnest by `.*`
- getting another `Array[Struct[T]]` that needs to be first flatten, then `.*`

> [!Example]- `generalise_explode`
> ![[3_hidden/_images/Pasted image 20230226191843.png]]

---
## Generalise Normalise Step 

By `flatten_schema` and `generalise_explode`, this comprise of a single step to handle one column: 
- explode/ flatten-explode first
- unnest by (`.*`)
- rename columns to retain parent-child relationship, i.e., `parent|child` column

> [!Example]- One explode-unnest step
> ![[3_hidden/_images/Pasted image 20230226192854.png]]

---
## main Function 

The finalise single function would do the following: 
1. analysis all the columns - get `flatten_schema` info
2. determine explode orders, closer to root explode first, then move up
3. recursively explode the fields, according to the orders

![[3_hidden/_images/Pasted image 20230226193205.png]]

---
## ℹ️ Resources
- [[🔖 learn-spark|Current Location]] ([.nb](https://github.com/tobytoyin/learn-spark/blob/main/pyspark/flatten_unnesting/flatten_schema.ipynb))  